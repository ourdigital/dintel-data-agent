""" Logging configuration module. Provides logging configuration for use throughout the project. """ import os import logging import yaml from logging.handlers import RotatingFileHandler, TimedRotatingFileHandler from typing import Dict, Any, Optional from pathlib import Path def load_config(config_path: str = "config/pipeline_config.yaml") -> Dict[str, Any]: """ Load configuration file. Parameters ---------- config_path: str Configuration file path Returns ------- Dict[str, Any] Dictionary containing configuration information """ try: with open(config_path, 'r', encoding='utf-8') as f: config = yaml.safe_load(f) return config except Exception as e: # Use default logging (when configuration file loading fails) print(f"Warning: Configuration file loading failed: {e}. Using default logging configuration.") return { 'logging': { 'level': 'INFO', 'log_to_file': True, 'log_file': 'logs/pipeline.log', 'rotate_logs': True, 'max_log_size_mb': 10 } } def setup_logging(config_path: str = "config/pipeline_config.yaml", log_name: Optional[str] = None) -> logging.Logger: """ Set up logging system. Parameters ---------- config_path: str Configuration file path log_name: str, optional Logger name. If None, set up root logger. Returns ------- logging.Logger Configured logger object """ # Load configuration config = load_config(config_path) log_config = config.get('logging', {}) # Get logging level level_str = log_config.get('level', 'INFO') level_map = { 'DEBUG': logging.DEBUG, 'INFO': logging.INFO, 'WARNING': logging.WARNING, 'ERROR': logging.ERROR, 'CRITICAL': logging.CRITICAL } log_level = level_map.get(level_str, logging.INFO) # Get logger logger = logging.getLogger(log_name) logger.setLevel(log_level) # Remove all existing handlers for handler in logger.handlers[:]: logger.removeHandler(handler) # Create default formatter formatter = logging.Formatter( '%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S' ) # Add console handler console_handler = logging.StreamHandler() console_handler.setFormatter(formatter) console_handler.setLevel(log_level) logger.addHandler(console_handler) # If file logging is enabled if log_config.get('log_to_file', True): log_file = log_config.get('log_file', 'logs/pipeline.log') # Create log directory log_dir = os.path.dirname(log_file) os.makedirs(log_dir, exist_ok=True) # Log rotation setup if log_config.get('rotate_logs', True): # Size-based rotation max_size_mb = log_config.get('max_log_size_mb', 10) max_size_bytes = max_size_mb * 1024 * 1024 backup_count = log_config.get('backup_count', 3) file_handler = RotatingFileHandler( log_file, maxBytes=max_size_bytes, backupCount=backup_count, encoding='utf-8' ) else: # Regular file handler file_handler = logging.FileHandler(log_file, encoding='utf-8') file_handler.setFormatter(formatter) file_handler.setLevel(log_level) logger.addHandler(file_handler) # Propagation setting (if not root logger) if log_name is not None: logger.propagate = log_config.get('propagate', False) return logger def get_logger(name: str, config_path: str = "config/pipeline_config.yaml") -> logging.Logger: """ Get logger with specified name. Parameters ---------- name: str Logger name config_path: str Configuration file path Returns ------- logging.Logger Logger object """ return setup_logging(config_path, name) # Usage example if __name__ == "__main__": # Set up root logger root_logger = setup_logging() root_logger.info("Root logger has been configured.") # Get logger for specific module module_logger = get_logger("data_pipeline") module_logger.debug("This is a debug message.") module_logger.info("This is an info message.") module_logger.warning("This is a warning message.") module_logger.error("This is an error message.") module_logger.critical("This is a critical error message.") # Get logger for another module another_logger = get_logger("data_analysis") another_logger.info("Logger for another module has been configured.") print("Logging configuration completed. Please check the 'logs/pipeline.log' file.")